var pam = function(arr,f) {
    return map(f,arr)
};

var score = function(erp, x) {
    // for backwards compatibility with webppl < 0.7
    //return Math.max(erp.score(null, x), erp.score(x));
    // NB: ^ isn't bullet proof
    erp.score(x)
}

var exp = function(x) {
    return Math.exp(x);
}

var expectation = function(erp) {
    sum(map(function(state) { return exp(score(erp, state)) * state },
            erp.support()))
}

// This does not assume numerical support values. It can accept any object as
// long as it has a 'val' field from which the expectation will be computed.
// This allows including additional information in the return values of a
// computation
var expectation2 = function(erp) {
    sum(map(function(state) { return exp(score(erp, state)) * state.val },
            erp.support()))
}

var variance = function(erp) {
    var mean = expectation(erp)

    sum(map(function(state) { return exp(score(erp, state)) * (state - mean)*(state-mean) },
            erp.support()))
}

var Model = function(name, f) {
    Object.defineProperty(f, 'name', {value: name})
    return f;
};

// Given a name: thunk object, Models will name each function
var Models = function(obj) {
    return map(function(key) {
        return Model(key, obj[key]);
    }, Object.keys(obj));
};

var getBestExpt = function(expts) {
    return reduce(function(expt, currMax) {
        return (expt.EIG > currMax.EIG) ? expt : currMax;
    }, {x: null, EIG: -Infinity}, expts);
};

// TODO: using this on priors and posteriors Just Works when the supports
// are {name: ..., func: ...} objects, which is a little surprising
// figure out why this works
var KL = function(P, Q) {
    var statesP = P.support();
    var statesQ = Q.support();

    // TODO: assert that states1 = states2
    return sum(map(
        function(state) {
            var scoreP = score(P, state), scoreQ = score(Q, state);
            var probP = exp(scoreP);
            // P(i) * log[ P(i) / Q(i) ] =  P(i) * [log(P(i) - log(Q(i)))]
            // Let \lim_{x \to 0} x \log(x) = 0.
            // Otherwise, 0 * -Infinity = NaN.
            if (probP === 0) {
                return 0;
            }
            return probP * (scoreP - scoreQ);
        },
        statesP));
}

var updatePosterior = function(args) {
    var M = args.M,
        x = args.x,
        y = args.y;

    var infer = args.infer || {},
        inferM1 = infer.M1 || Enumerate,
        inferM2 = infer.M2 || Enumerate;

    var mPrior = args.mPrior || inferM1(function() {
        var m = M();
        return {name: m.name, func: m};
    });

    var mPosterior = inferM2(function() {
        var mData = sample(mPrior), mName = mData.name, mFunc = mData.func;
        var LL = mFunc(x,y);
        factor(LL);
        return mData;
    });

    return {
        mPosterior: mPosterior,
        AIG: KL(mPosterior, mPrior)
    };
};

// compute actual information gain
var AIG = function(args) {
    return updatePosterior(args).AIG;
};

// notes: doesn't seem to work with incrementalMH right now
var EIG = function(args) {
    var M = args.M, X = args.X, Y = args.Y;
    // example: could use MH for M1 but then enumerate for M2
    var infer = args.infer || {},
        inferX = infer.X || Enumerate,
        inferY = infer.Y || Enumerate,
        inferM1 = infer.M1 || Enumerate,
        inferM2 = infer.M2 || Enumerate,
        mFuncs = args.mFuncs,
        usePredictiveY = !!args.usePredictiveY,
        returnKL = !!args.returnKL;

    // Construct mPrior either 1) if it's provided in args, or 2) from the
    // model sample function. Note that args.mPrior overrides args.M if both
    // are present
    var mPrior = args.mPrior || inferM1(function() {
        var m = M();
        return {name: m.name, func: m};
    });

    inferX(function() {
        var x = X();
        // wrt the above distribution on responses, what is the posterior distribution on models?
        var KLDist = inferY(function() {
            var y = Y(x);
            if (args.usePredictiveY) {
                var _m = sample(mPrior), mName = _m.name, mFunc = _m.func;
                var scoreY = mFunc(x,y);
                factor(scoreY);
            }
            // TODO: For OED with discrete responses y, return mPosteriors
            // in EIG to prevent recomputing during updatePosterior?
            var mPosterior = inferM2(function() {
                var _m2 = sample(mPrior), m2Name = _m2.name, m2Func = _m2.func;
                var ll = m2Func(x,y);
                factor(ll);
                return _m2;
            });
            var kl = KL(mPosterior, mPrior);
            return {y: y, val: kl};
        });

        // is there a way of getting confidence intervals around eig?
        var EIG = expectation2(KLDist);
        factor(EIG);
        // var VIG = variance(KLDist);
        // return {x: x, EIG: EIG, VIG: VIG}
        return (returnKL) ? {x: x, EIG: EIG, KLDist: KLDist} : {x: x, EIG: EIG}
    })
}

var OED = EIG;
